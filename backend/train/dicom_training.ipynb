{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd211ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.5.1+cu121\n",
      "12.1\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8eda44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Check Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33838af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "No Lung Opacity / Not Normal    11821\n",
      "Lung Opacity                     9555\n",
      "Normal                           8851\n",
      "Name: count, dtype: int64\n",
      "Target\n",
      "0    20672\n",
      "1     9555\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Load labels ---\n",
    "labels = pd.read_csv(\"../../dataset/rsna/rsna_detailed_class_info.csv\") \n",
    "\n",
    "labels['Target'] = labels['class'].map({\n",
    "    'Lung Opacity': 1,\n",
    "    'No Lung Opacity / Not Normal': 0,\n",
    "    'Normal': 0\n",
    "})\n",
    "\n",
    "\n",
    "print(labels['class'].value_counts())\n",
    "print(labels['Target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e728fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Dataset ---\n",
    "class RSNADataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        dcm_path = os.path.join(self.root_dir, row['patientId'] + '.dcm')\n",
    "        dcm = pydicom.dcmread(dcm_path)\n",
    "        image = dcm.pixel_array.astype(np.float32)\n",
    "        image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "        image = np.stack([image] * 3, axis=-1)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, row['Target']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1caa7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transforms ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "])\n",
    "\n",
    "# --- Data Split ---\n",
    "train_df, val_df = train_test_split(labels, test_size=0.2, stratify=labels['Target'])\n",
    "\n",
    "# --- Datasets and Loaders ---\n",
    "train_ds = RSNADataset(train_df, \"../../dataset/rsna/train_dicom\", transform)\n",
    "val_ds = RSNADataset(val_df, \"../../dataset/rsna/train_dicom\", transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a770ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kunal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kunal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# --- Model Setup ---\n",
    "model = resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b279d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1512/1512 [11:02<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete. Avg Loss: 0.4077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1512/1512 [09:38<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete. Avg Loss: 0.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1512/1512 [09:27<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete. Avg Loss: 0.2994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1512/1512 [09:02<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete. Avg Loss: 0.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1512/1512 [09:03<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete. Avg Loss: 0.1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} complete. Avg Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "decaf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Model ---\n",
    "# os.makedirs(\"train/models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"models/dicom_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f9ddeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 378/378 [02:31<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Validation Accuracy: 85.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Validation Block ---\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\n✅ Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
